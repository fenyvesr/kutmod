\begin{multicols*}{2}
	[\section{Introduction}]
	Product Development is driven by stakeholder requirements. The larger the developed system, the harder it is to analyze and verify it. Software Projects are no exceptions. This project aims to show how the verification of huge software projects can be performed automatically against the given requirements. The project spreads across multiple areas of main stream research.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{../Architecture}
		\caption[PorjArch]{Project Architecture}
		\label{fig:architecture}
	\end{figure}
	
	\gls{NLP} is used for formalizing the \gls{SRS}. Since, natural language is widely understood by stakeholders, it is used as a common way for representing requirements. Representing requirements in natural language suffers from potential problems like ambiguity, inconsistency and incompleteness.
	
	A systematic literature review in the last two decades from 1995 till 2016 shows that collecting ambiguous requirements is one of the highest critical challenges in software engineering \cite{Besrour}. Since the advent of software engineering, researchers used formal and semi-formal methods to overcome this problem. However, even when formal and semi-formal languages are used, there is no escape from natural language as the initial requirements are written in natural language \cite{Kamsties}.
	
	The consequences of ambiguous requirements will lead to excessive efforts, high cost and failure in some software projects. For example, software developers might decide a subjective interpretation of requirements based on their point of view. Ferrari et al. (2014) argued that this subjective interpretation leads to designing software in a different way from what was intended in the requirements \cite{Ferrari}.
	
	For several decades, \gls{SRS} processing and analysis has been the focus of research in software engineering discipline. Since natural language is ambiguous, a computer cannot provide full support to analyze \gls{SRS} in an automatic fashion. Consequently, the analysis of \gls{SRS} is conducted manually which consumes time, effort and cost. Most importantly, the manual analysis of requirements results in inefficiency and imprecise results \cite{Wang}. The problem will be more obvious and critical when software projects involve thousands of requirements and hundreds of \gls{SRS} documents. Conducting verification of thousands of requirements via humans will become extremely expensive \cite{Fanmuy}.
	
	Generally, the primary source of problems in requirement engineering is reliance on humans extensively \cite{Ahmed}. This discussion leads to the importance of finding an automatic way for processing \gls{SRS}. \gls{NLP} is used as a possible solution to resolve ambiguity and to provide valuable information to the intended software developers.
	
	Ryan (1993) argued that: ”It is highly questionable that the resulting system from \gls{NLP} would be of great use in requirements engineering” \cite{Ryan}.
	
	Nazir et al. (2017) conducted a systematic literature review on \gls{NLP} applications for software requirement engineering and he concluded that: “Manual operations are still required on initial plain text of software requirements before applying the desired \gls{NLP} techniques” \cite{Nazir}.
	
	Besides the \gls{NLP}, our work can create and analyze the formal semantics of the source code.  A formal semantics should serve as a solid foundation for any programming language development, so it must be correct and complete (to be trusted and useful), executable (to yield a reference implementation), and appropriate for program reasoning and verification.
	
	Several efforts to give C a formal semantics have been made, most notably by Charles McEwen Ellison (III.). His executable formal semantics of the C language successfully passes  99.2\% of 776 test programs \cite{Ellison:2012:EFS:2103621.2103719}. Having to define two or more different semantics for a real-life language, together with proofs of equivalence, is a huge burden in itself, not to mention that these all need to be maintained as the language evolves.
	
	Currently code validation falls into two categories: testing and formal verification. Formal verification mainly includes two methods: theorem proving and model checking.
	
	Theorem Proving requires considerable expertise to guide and assist the verification process, and can not generate counter-examples that are useful for debugging when the verification fails.
	
	Model Checking \cite{Clarke:2000:MC:332656} is an automatic formal verification technique for a finite state system, where all the states of the system are exhaustively enumerated and the correctness condition checked at each state. Moreover, model checking yields extremely useful counter examples if it fails. It has proven effective in detecting errors in hardware designs.
	
	Software model checking could produce major enhancements in software reliability and robustness. However, the state space of software programs is typically so huge that they cannot be directly model checked with conventional model checking methods. Fortunately, applying mathematically abstraction methods might extract a reduced model from a program which makes model checking feasible.
	
	Our goal is to tackle multiple problems listed above. Design and train an \gls{NLP} for reliably analyzing the requirements and to verify the semantics of the C source code against the given requirements.
	
\end{multicols*}

